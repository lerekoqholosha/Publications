{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creating a machine learning pipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP-fWmufE615"
      },
      "source": [
        "##Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1-nAwTVC_UQ"
      },
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q59oaYSsFcaH"
      },
      "source": [
        "Let's look at data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDYixcaUFP3M"
      },
      "source": [
        "iris=load_iris()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Vl6DPEFleq",
        "outputId": "e914741a-fcc2-492a-fd3c-6562da26acbe"
      },
      "source": [
        "#look at features\n",
        "iris.data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKv2fFbxFrVv",
        "outputId": "6b9fb93a-3ba6-4708-cc85-5c4f1a8dc020"
      },
      "source": [
        "#target\n",
        "iris.target"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfoHqeB4F2og"
      },
      "source": [
        "**Spliting data into training and testing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfIYgfejFyqY"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(iris.data,iris.target,test_size=.2,random_state=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPAotDUvGfdA"
      },
      "source": [
        "**Creating a pipelines for our models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sh3wmTxNsst"
      },
      "source": [
        "`Pipelines Creation`\n",
        "1. Data Preprocessing by using Standard Scaler\n",
        "2. Reduce Dimension using PCA\n",
        "3. Apply  Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSNRf5leOnc1"
      },
      "source": [
        "pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n",
        "                     ('pca1',PCA(n_components=2)),\n",
        "                     ('lr_classifier',LogisticRegression())])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8eEhe7uOnXi"
      },
      "source": [
        "pipeline_dt=Pipeline([('scalar2',StandardScaler()),\n",
        "                     ('pca2',PCA(n_components=2)),\n",
        "                     ('dt_classifier',DecisionTreeClassifier(random_state=0))])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7s2rWWHOnTC"
      },
      "source": [
        "pipeline_randomforest=Pipeline([('scalar3',StandardScaler()),\n",
        "                     ('pca3',PCA(n_components=2)),\n",
        "                     ('rf_classifier',RandomForestClassifier(random_state=0))])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcWiDSNR95Qj"
      },
      "source": [
        "## LEts make the list of pipelines\n",
        "pipelines = [pipeline_lr, pipeline_dt, pipeline_randomforest]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr7iWqvl99QY"
      },
      "source": [
        "best_accuracy=0.0\n",
        "best_classifier=0\n",
        "best_pipeline=\"\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCQKQ6NPOD-q"
      },
      "source": [
        "# Dictionary of pipelines and classifier types for ease of reference\n",
        "pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest'}\n",
        "\n",
        "# Fit the pipelines\n",
        "for pipe in pipelines:\n",
        "\tpipe.fit(X_train, y_train)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHyWpmDTPcYo"
      },
      "source": [
        "**let's look at accuracy**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvfYR7tNKvEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83201c3-88dd-4f01-900c-891c7bc7e268"
      },
      "source": [
        "for i,model in enumerate(pipelines):\n",
        "    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(X_test,y_test)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Test Accuracy: 0.9666666666666667\n",
            "Decision Tree Test Accuracy: 0.9333333333333333\n",
            "RandomForest Test Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jGGcQKwPiRS",
        "outputId": "4d8692dd-e72e-4155-fbe9-66a3cb14fc6d"
      },
      "source": [
        "for i,model in enumerate(pipelines):\n",
        "    if model.score(X_test,y_test)>best_accuracy:\n",
        "        best_accuracy=model.score(X_test,y_test)\n",
        "        best_pipeline=model\n",
        "        best_classifier=i\n",
        "print('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier with best accuracy:Logistic Regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KfakATMPwEh"
      },
      "source": [
        "##Pipelines Perform Hyperparameter Tuning Using Grid SearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og6GN7JwPo4L"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o6sOxuXEgzY",
        "outputId": "e5731dda-e602-4cda-f9e3-b730e409c38c"
      },
      "source": [
        "# Create a pipeline\n",
        "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
        "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
        "grid_param = [\n",
        "                {\"classifier\": [LogisticRegression()],\n",
        "                 \"classifier__penalty\": ['l2','l1'],\n",
        "                 \"classifier__C\": np.logspace(0, 4, 10)\n",
        "                 },\n",
        "                {\"classifier\": [LogisticRegression()],\n",
        "                 \"classifier__penalty\": ['l2'],\n",
        "                 \"classifier__C\": np.logspace(0, 4, 10),\n",
        "                 \"classifier__solver\":['newton-cg','saga','sag','liblinear'] ##This solvers don't allow L1 penalty\n",
        "                 },\n",
        "                {\"classifier\": [RandomForestClassifier()],\n",
        "                 \"classifier__n_estimators\": [10, 100, 1000],\n",
        "                 \"classifier__max_depth\":[5,8,15,25,30,None],\n",
        "                 \"classifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
        "                 \"classifier__max_leaf_nodes\": [2, 5,10]}]\n",
        "# create a gridsearch of the pipeline, the fit the best model\n",
        "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
        "best_model = gridsearch.fit(X_train,y_train)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "50 fits failed out of a total of 1920.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "50 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.96666667        nan 0.975             nan 0.975             nan\n",
            " 0.975             nan 0.95833333        nan 0.95              nan\n",
            " 0.95              nan 0.95              nan 0.95              nan\n",
            " 0.95              nan 0.96666667 0.98333333 0.98333333 0.93333333\n",
            " 0.975      0.98333333 0.975      0.95833333 0.975      0.975\n",
            " 0.975      0.95833333 0.975      0.975      0.96666667 0.94166667\n",
            " 0.95833333 0.975      0.96666667 0.94166667 0.95833333 0.975\n",
            " 0.96666667 0.94166667 0.95833333 0.975      0.96666667 0.94166667\n",
            " 0.95833333 0.975      0.96666667 0.94166667 0.95       0.96666667\n",
            " 0.96666667 0.94166667 0.95       0.975      0.96666667 0.94166667\n",
            " 0.88333333 0.75833333 0.86666667 0.725      0.86666667 0.9\n",
            " 0.8        0.84166667 0.9        0.85       0.89166667 0.9\n",
            " 0.83333333 0.85       0.9        0.35833333 0.36666667 0.36666667\n",
            " 0.95833333 0.95       0.94166667 0.94166667 0.95       0.94166667\n",
            " 0.95       0.93333333 0.93333333 0.925      0.95       0.94166667\n",
            " 0.94166667 0.96666667 0.94166667 0.36666667 0.36666667 0.36666667\n",
            " 0.93333333 0.94166667 0.94166667 0.94166667 0.93333333 0.94166667\n",
            " 0.93333333 0.95       0.93333333 0.93333333 0.94166667 0.94166667\n",
            " 0.93333333 0.95       0.94166667 0.36666667 0.36666667 0.36666667\n",
            " 0.83333333 0.90833333 0.9        0.85833333 0.90833333 0.9\n",
            " 0.85       0.85       0.90833333 0.84166667 0.90833333 0.86666667\n",
            " 0.84166667 0.89166667 0.9        0.36666667 0.36666667 0.36666667\n",
            " 0.94166667 0.93333333 0.94166667 0.94166667 0.93333333 0.94166667\n",
            " 0.96666667 0.95       0.93333333 0.95       0.95       0.94166667\n",
            " 0.96666667 0.94166667 0.93333333 0.36666667 0.36666667 0.36666667\n",
            " 0.93333333 0.93333333 0.94166667 0.95       0.94166667 0.94166667\n",
            " 0.95       0.95       0.93333333 0.93333333 0.96666667 0.93333333\n",
            " 0.95       0.95       0.95833333 0.36666667 0.36666667 0.36666667\n",
            " 0.81666667 0.93333333 0.9        0.86666667 0.80833333 0.875\n",
            " 0.89166667 0.85833333 0.90833333 0.80833333 0.825      0.9\n",
            " 0.83333333 0.91666667 0.89166667 0.35       0.36666667 0.36666667\n",
            " 0.95       0.94166667 0.94166667 0.95       0.94166667 0.94166667\n",
            " 0.95833333 0.93333333 0.93333333 0.925      0.95       0.93333333\n",
            " 0.95       0.96666667 0.95       0.36666667 0.36666667 0.36666667\n",
            " 0.94166667 0.94166667 0.94166667 0.94166667 0.94166667 0.94166667\n",
            " 0.94166667 0.94166667 0.94166667 0.94166667 0.94166667 0.94166667\n",
            " 0.93333333 0.95833333 0.94166667 0.35       0.36666667 0.36666667\n",
            " 0.78333333 0.875      0.9        0.86666667 0.9        0.9\n",
            " 0.86666667 0.81666667 0.9        0.85833333 0.875      0.9\n",
            " 0.89166667 0.93333333 0.89166667 0.34166667 0.36666667 0.36666667\n",
            " 0.93333333 0.94166667 0.94166667 0.96666667 0.94166667 0.94166667\n",
            " 0.93333333 0.95833333 0.93333333 0.94166667 0.95833333 0.94166667\n",
            " 0.95       0.95       0.95       0.36666667 0.36666667 0.36666667\n",
            " 0.93333333 0.93333333 0.94166667 0.94166667 0.93333333 0.94166667\n",
            " 0.94166667 0.94166667 0.93333333 0.94166667 0.95       0.94166667\n",
            " 0.925      0.94166667 0.94166667 0.36666667 0.36666667 0.36666667\n",
            " 0.8        0.84166667 0.9        0.79166667 0.89166667 0.9\n",
            " 0.76666667 0.875      0.875      0.84166667 0.89166667 0.86666667\n",
            " 0.88333333 0.88333333 0.9        0.36666667 0.36666667 0.36666667\n",
            " 0.95       0.94166667 0.94166667 0.94166667 0.94166667 0.94166667\n",
            " 0.94166667 0.93333333 0.93333333 0.93333333 0.94166667 0.94166667\n",
            " 0.96666667 0.94166667 0.94166667 0.36666667 0.36666667 0.36666667\n",
            " 0.93333333 0.94166667 0.94166667 0.95       0.94166667 0.94166667\n",
            " 0.95       0.94166667 0.93333333 0.94166667 0.94166667 0.94166667\n",
            " 0.93333333 0.94166667 0.95       0.36666667 0.36666667 0.36666667\n",
            " 0.79166667 0.81666667 0.9        0.85       0.9        0.90833333\n",
            " 0.9        0.95       0.89166667 0.85       0.9        0.9\n",
            " 0.90833333 0.9        0.9        0.33333333 0.36666667 0.36666667\n",
            " 0.93333333 0.93333333 0.94166667 0.95833333 0.93333333 0.94166667\n",
            " 0.94166667 0.93333333 0.93333333 0.95       0.94166667 0.93333333\n",
            " 0.93333333 0.94166667 0.95833333 0.36666667 0.36666667 0.36666667\n",
            " 0.95       0.93333333 0.94166667 0.94166667 0.93333333 0.94166667\n",
            " 0.925      0.94166667 0.93333333 0.94166667 0.93333333 0.94166667\n",
            " 0.94166667 0.95       0.94166667 0.36666667 0.36666667 0.36666667]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi5ga-8hDlIJ",
        "outputId": "5974d3c8-96d6-47bc-8242-d978e792192a"
      },
      "source": [
        "print(best_model.best_estimator_)\n",
        "print(\"The mean accuracy of the model is:\",best_model.score(X_test,y_test))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline(steps=[('classifier', LogisticRegression(solver='saga'))])\n",
            "The mean accuracy of the model is: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiWtk_KBGwK_"
      },
      "source": [
        "##MakePipelines In SKLearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjT-l1K3HXGa"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlVJwfGJEpV6"
      },
      "source": [
        "# Create a pipeline\n",
        "pipe = make_pipeline((RandomForestClassifier()))\n",
        "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
        "grid_param = [\n",
        "                {\"randomforestclassifier\": [RandomForestClassifier()],\n",
        "                 \"randomforestclassifier__n_estimators\": [10, 100, 1000],\n",
        "                 \"randomforestclassifier__max_depth\":[5,8,15,25,30,None],\n",
        "                 \"randomforestclassifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
        "                 \"randomforestclassifier__max_leaf_nodes\": [2, 5,10]}]\n",
        "# create a gridsearch of the pipeline, the fit the best model\n",
        "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
        "best_model = gridsearch.fit(X_train,y_train)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAlRC2AsEpQE",
        "outputId": "819e2fc0-b7f6-4d3e-d1ee-433981732e58"
      },
      "source": [
        "best_model.score(X_test,y_test)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}